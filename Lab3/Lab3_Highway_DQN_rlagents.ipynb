{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lab3 Highway DQN rlagents",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lars-x/Umu_Labs/blob/main/Lab3/Lab3_Highway_DQN_rlagents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTBW2COTwOg_"
      },
      "source": [
        "Lab3 is based on highway-env https://github.com/eleurent/highway-env. In \n",
        "envs/highway_env.py, the vehicle is rewarded for reaching a high speed, staying on the rightmost lanes and avoiding collisions for in highway driving (highway-env). Your task is to add an additional term to penalize changing lanes. (Ideally we should penalize changing lanes to the left more than changing to the right, but this is a simplified exercise.) Please refer to envs/roundabout_env for reference.\n",
        "\n",
        "Steps:\n",
        "\n",
        "1) Fork the highway-env repository to your own GitHub account, and modify highway_env.py. (if you are not familiar with GitHub, I recommend installing GitHub Desktop https://desktop.github.com.)\n",
        "\n",
        "2) Replace \n",
        "!pip install highway-env \n",
        "with path to your own repository:\n",
        "!pip install git+https://github.com/USERNAME/highway-env\n",
        "\n",
        "3) Train your agent for different values of lane_change_reward, and different environments with varying complexity, starting from the simplest:\n",
        "\n",
        "env.config[\"lane_change_reward\"] = 0\n",
        "\n",
        "env.config[\"vehicles_count\"] = 0\n",
        "\n",
        "env.config[\"lanes_count\"] = 2\n",
        "\n",
        "env.config[\"initial_lane_id\"] = 0\n",
        "\n",
        "In this simple environment, during testing the vehicle should switch to the right lane quickly and stay in the right lane. (It is possible for it to stay in the left lane during testing if your training num_episodes is too small, since the agent may not have had a chance to try the lane change action during training.)\n",
        "Try different values of lane_change_reward (e.g., -0.1, -1, -10, etc. note that it must be negative), and different numbers of vehicles/lanes. Make lane_change_reward very negative until you observe that the vehicle prefers *collision* to *lane change to avoid collision*. Submit your IPython Notebook, and a short report (or text blocks within the Notebook) describing the different configurations you have tried (at least three), and your observations for each config.\n",
        "\n",
        "Notes: \n",
        "\n",
        "1) More complex environments demand more training time (more num_episodes), so do not make your environment more complex than necessary. You may try increasing the  vehicles_density and reward_speed_range to increase the chances of collision. You may also find \"Script to Stop Google Colab From Disconnecting\" to be helpful.\n",
        "\n",
        "2) You may want to tune DQN hyperparams in configs/HighwayEnv/agents/DQNAgent/dqn.json, e.g., discount factor gamma, and epsilon greedy exploration params tau, temperature, final_temperature for different num_episodes.\n",
        "\n",
        "3) The error message \"fatal: destination path 'highway-env' already exists and is not an empty directory\" in the first code cell can be safely ignored.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sepDWoBqdRMK"
      },
      "source": [
        "# Training a DQN on `highway-v0` with rlagents\n",
        "## Import requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx8X4s8krNWt",
        "outputId": "53a06493-3441-4fa0-ea8a-1ba19774d15b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Environment\n",
        "!pip install highway-env\n",
        "#!pip install git+https://github.com/lars-x/highway-env\n",
        "import gym\n",
        "import highway_env\n",
        "\n",
        "# Agent\n",
        "!pip install git+https://github.com/eleurent/rl-agents\n",
        "\n",
        "# Visualisation utils\n",
        "import sys\n",
        "%load_ext tensorboard\n",
        "!pip install tensorboardx gym pyvirtualdisplay\n",
        "!apt-get install -y xvfb python-opengl ffmpeg\n",
        "!git clone https://github.com/eleurent/highway-env.git\n",
        "sys.path.insert(0, '/content/highway-env/scripts/')\n",
        "from utils import show_videos"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting highway-env\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/2e/2009abe2db56afca5c9058c205da6429d7c168d792691d3d5cd40c214f14/highway_env-1.2-py3-none-any.whl (92kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from highway-env) (0.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from highway-env) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from highway-env) (1.1.5)\n",
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/9e/c400554dd1d0e562bd4379f35ad5023c68fc120003a58991405850f56f95/pygame-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 243kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from highway-env) (3.2.2)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->highway-env) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->highway-env) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->highway-env) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->highway-env) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->highway-env) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->highway-env) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->highway-env) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->highway-env) (2.4.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->highway-env) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->highway-env) (1.15.0)\n",
            "Installing collected packages: pygame, highway-env\n",
            "Successfully installed highway-env-1.2 pygame-2.0.1\n",
            "Collecting git+https://github.com/eleurent/rl-agents\n",
            "  Cloning https://github.com/eleurent/rl-agents to /tmp/pip-req-build-fz681mly\n",
            "  Running command git clone -q https://github.com/eleurent/rl-agents /tmp/pip-req-build-fz681mly\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (0.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (1.1.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (0.51.2)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (0.11.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (0.6.2)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from rl-agents==1.0.dev0) (1.8.1+cu101)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->rl-agents==1.0.dev0) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->rl-agents==1.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->rl-agents==1.0.dev0) (1.5.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->rl-agents==1.0.dev0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->rl-agents==1.0.dev0) (2.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->rl-agents==1.0.dev0) (56.1.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->rl-agents==1.0.dev0) (0.34.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->rl-agents==1.0.dev0) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->rl-agents==1.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->rl-agents==1.0.dev0) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2.0->rl-agents==1.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->rl-agents==1.0.dev0) (3.12.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->rl-agents==1.0.dev0) (0.16.0)\n",
            "Building wheels for collected packages: rl-agents\n",
            "  Building wheel for rl-agents (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rl-agents: filename=rl_agents-1.0.dev0-cp37-none-any.whl size=114548 sha256=08c0d7e550cec9b226d9870b6e4cba01bc82a01d14c6d3210b445e33710bf457\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s_xrypr_/wheels/be/14/44/bc2b8a73d904f2a421fde80db171e2bae90dfee95f293befca\n",
            "Successfully built rl-agents\n",
            "Installing collected packages: tensorboardX, rl-agents\n",
            "Successfully installed rl-agents-1.0.dev0 tensorboardX-2.2\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.7/dist-packages (2.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/19/88/7a198a5ee3baa3d547f5a49574cd8c3913b216f5276b690b028f89ffb325/PyVirtualDisplay-2.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardx) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardx) (3.12.4)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Collecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx) (56.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.3 pyvirtualdisplay-2.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl xvfb\n",
            "0 upgraded, 2 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 1,281 kB of archives.\n",
            "After this operation, 7,686 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.9 [784 kB]\n",
            "Fetched 1,281 kB in 2s (521 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 160706 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Cloning into 'highway-env'...\n",
            "remote: Enumerating objects: 7510, done.\u001b[K\n",
            "remote: Counting objects: 100% (149/149), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 7510 (delta 66), reused 117 (delta 57), pack-reused 7361\u001b[K\n",
            "Receiving objects: 100% (7510/7510), 22.15 MiB | 10.96 MiB/s, done.\n",
            "Resolving deltas: 100% (5142/5142), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvOEW00pdHrG"
      },
      "source": [
        "## Training\n",
        "\n",
        "Prepare environment, agent, and evaluation process.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QowKW3ix45ZW"
      },
      "source": [
        "from rl_agents.trainer.evaluation import Evaluation\n",
        "from rl_agents.agents.common.factory import load_agent, load_environment\n",
        "\n",
        "# Get the environment and agent configurations from the rl-agents repository\n",
        "!git clone https://github.com/eleurent/rl-agents.git\n",
        "%cd /content/rl-agents/scripts/\n",
        "env_config = 'configs/HighwayEnv/env.json'\n",
        "agent_config = 'configs/HighwayEnv/agents/DQNAgent/dqn.json'\n",
        "\n",
        "env = load_environment(env_config)\n",
        "import pprint\n",
        "from matplotlib import pyplot as plt\n",
        "env.config[\"lane_change_reward\"] = 0\n",
        "env.config[\"vehicles_count\"] = 0\n",
        "#env.config['reward_speed_range'] = [0, 100]\n",
        "env.config[\"lanes_count\"] = 2\n",
        "env.config[\"initial_lane_id\"] = 0\n",
        "pprint.pprint(env.config)\n",
        "pprint.pprint(agent_config)\n",
        "\n",
        "env.reset()\n",
        "plt.imshow(env.render(mode=\"rgb_array\"))\n",
        "plt.show()\n",
        "\n",
        "agent = load_agent(agent_config, env)\n",
        "evaluation = Evaluation(env, agent, num_episodes=10, display_env=False)\n",
        "print(f\"Ready to train {agent} on {env}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtK9dtfb0JMF"
      },
      "source": [
        "Start training. Run tensorboard locally to visualize training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFVq1gFz42Eg"
      },
      "source": [
        "%tensorboard --logdir \"{evaluation.directory}\"\n",
        "evaluation.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lNvWg42RWiw"
      },
      "source": [
        "Progress can be visualised in the tensorboard cell above, which should update every 30s (or manually). You may need to click the *Fit domain to data* buttons below each graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKfvu5uhzCIU"
      },
      "source": [
        "## Testing\n",
        "\n",
        "Run the learned policy for a few episodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY0rpVYUtRpN"
      },
      "source": [
        "#env = load_environment(env_config)\n",
        "env.configure({\"offscreen_rendering\": True})\n",
        "agent = load_agent(agent_config, env)\n",
        "evaluation = Evaluation(env, agent, num_episodes=3, recover=True)\n",
        "evaluation.test()\n",
        "show_videos(evaluation.run_directory)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}